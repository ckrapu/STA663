{
 "metadata": {
  "name": "",
  "signature": "sha256:51e0f80d571cf3ce22ad5effa38d451f92079ef3c57e56e01f0d313a8ab5b1fa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "%matplotlib inline\n",
      "%precision 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "u'%.4f'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data science is OSEMN\n",
      "----\n",
      "\n",
      "According to a popular model, the elements of data science are\n",
      "\n",
      "- Obtaining data\n",
      "- Scrubbing data\n",
      "- Exploring data\n",
      "- Modeling data\n",
      "- iNterpreting data\n",
      "\n",
      "and hence the acronym OSEMN, pronounced as \"Awesome\".\n",
      "\n",
      "This lecture will review the O and S parts, often stated to consume between 50-80% of your time in a complex data analysis pipeline."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Obtaining data\n",
      "----\n",
      "\n",
      "Data may be generated from clinical trials, scientific experiments, surveys, web pages, computer simulations  etc. There are many ways that data can be stored, and part of the initial challenge is simply reading in the data so that it can be analysed."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Plain text files\n",
      "\n",
      "We can open plain text files with the `open` function. This is a common and very flexible format, but because no structure is involved, custom processing methods to extract the information needed may be necessary."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Example 1**: Suppose we want to find out how often the words alice and drink occur in the same sentence in Alice in Wonderland."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We first need to get the book from Project Gutenburg\n",
      "\n",
      "import os\n",
      "if not os.path.exists('alice.txt'):\n",
      "    ! wget http://www.gutenberg.org/cache/epub/11/pg11.txt -O alice.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now read the book into memory, clean out blank lines and convert to lowercase\n",
      "alice = open('alice.txt', 'r').read().replace('\\r\\n', '').lower()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split into sentence\n",
      "# simplistically assume that every sentence ends with a '.', '?' or '!'\n",
      "import re\n",
      "\n",
      "stop_pattern = '\\.|\\?|\\!'\n",
      "sentences = re.split(stop_pattern, alice)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find sentences that contain both 'alice' and 'drink'\n",
      "\n",
      "print\n",
      "\n",
      "for i, sentence in enumerate(sentences):\n",
      "    if 'alice' in sentence and 'drink' in sentence:\n",
      "        print i, sentence, '\\n'\n",
      "        \n",
      "string = \"cat\"\n",
      "print(string[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "66 there seemed to be no use in waiting by the little door, so she wentback to the table, half hoping she might find another key on it, or atany rate a book of rules for shutting people up like telescopes: thistime she found a little bottle on it, ('which certainly was not herebefore,' said alice,) and round the neck of the bottle was a paperlabel, with the words 'drink me' beautifully printed on it in largeletters \n",
        "\n",
        "67 it was all very well to say 'drink me,' but the wise little alice wasnot going to do that in a hurry \n",
        "\n",
        "469  alice looked all round her atthe flowers and the blades of grass, but she did not see anything thatlooked like the right thing to eat or drink under the circumstances \n",
        "\n",
        "882 ' said alice, who always took a great interest inquestions of eating and drinking \n",
        "\n",
        "a\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Delimited files\n",
      "\n",
      "Plain text files can also have a delimited structure - basically a table with rows and columns, where eacy column is separated by some separator, commonly a comma (CSV) or tab. There may or may not be additional comments or a header row in the file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file example.csv\n",
      "# This is a comment\n",
      "# This is another comment\n",
      "alice,60,1.56\n",
      "bob,72,1.75\n",
      "david,84,1.82"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting example.csv\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Using line by line parsing\n",
      "import csv\n",
      "\n",
      "with open('example.csv') as f:\n",
      "    # use a generator expression to strip out comments\n",
      "    for line in csv.reader(row for row in f if not row.startswith('#')):\n",
      "        name, wt, ht = line\n",
      "        wt, ht = map(float, (wt, ht))\n",
      "        print 'BMI of %s = %.2f' % (name, wt/(ht*ht))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BMI of alice = 24.65\n",
        "BMI of bob = 23.51\n",
        "BMI of david = 25.36\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Often it is most convenient to read it into a Pandas dataframe\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "df = pd.read_csv('example.csv', comment='#', header=None)\n",
      "df.columns = ['name', 'wt', 'ht']\n",
      "df['bmi'] = df['wt']/(df['ht']*df['ht'])\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>name</th>\n",
        "      <th>wt</th>\n",
        "      <th>ht</th>\n",
        "      <th>bmi</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> alice</td>\n",
        "      <td> 60</td>\n",
        "      <td> 1.56</td>\n",
        "      <td> 24.654832</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>   bob</td>\n",
        "      <td> 72</td>\n",
        "      <td> 1.75</td>\n",
        "      <td> 23.510204</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> david</td>\n",
        "      <td> 84</td>\n",
        "      <td> 1.82</td>\n",
        "      <td> 25.359256</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "    name  wt    ht        bmi\n",
        "0  alice  60  1.56  24.654832\n",
        "1    bob  72  1.75  23.510204\n",
        "2  david  84  1.82  25.359256"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### JSON files\n",
      "\n",
      "JSON is JavaScript Object Notation - a format used widely for web-based resource sharing. It is very similar in structure to a Python nested dictionary. Here is an example from http://json.org/example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file example.json\n",
      "{\n",
      "    \"glossary\": {\n",
      "        \"title\": \"example glossary\",\n",
      "\t\t\"GlossDiv\": {\n",
      "            \"title\": \"S\",\n",
      "\t\t\t\"GlossList\": {\n",
      "                \"GlossEntry\": {\n",
      "                    \"ID\": \"SGML\",\n",
      "\t\t\t\t\t\"SortAs\": \"SGML\",\n",
      "\t\t\t\t\t\"GlossTerm\": \"Standard Generalized Markup Language\",\n",
      "\t\t\t\t\t\"Acronym\": \"SGML\",\n",
      "\t\t\t\t\t\"Abbrev\": \"ISO 8879:1986\",\n",
      "\t\t\t\t\t\"GlossDef\": {\n",
      "                        \"para\": \"A meta-markup language, used to create markup languages such as DocBook.\",\n",
      "\t\t\t\t\t\t\"GlossSeeAlso\": [\"GML\", \"XML\"]\n",
      "                    },\n",
      "\t\t\t\t\t\"GlossSee\": \"markup\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting example.json\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "data = json.load(open('example.json'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# data is a nested Python dictionary\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "{u'glossary': {u'GlossDiv': {u'GlossList': {u'GlossEntry': {u'Abbrev': u'ISO 8879:1986',\n",
        "     u'Acronym': u'SGML',\n",
        "     u'GlossDef': {u'GlossSeeAlso': [u'GML', u'XML'],\n",
        "      u'para': u'A meta-markup language, used to create markup languages such as DocBook.'},\n",
        "     u'GlossSee': u'markup',\n",
        "     u'GlossTerm': u'Standard Generalized Markup Language',\n",
        "     u'ID': u'SGML',\n",
        "     u'SortAs': u'SGML'}},\n",
        "   u'title': u'S'},\n",
        "  u'title': u'example glossary'}}"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# and can be parsed using standard key lookups\n",
      "data['glossary']['GlossDiv']['GlossList']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "{u'GlossEntry': {u'Abbrev': u'ISO 8879:1986',\n",
        "  u'Acronym': u'SGML',\n",
        "  u'GlossDef': {u'GlossSeeAlso': [u'GML', u'XML'],\n",
        "   u'para': u'A meta-markup language, used to create markup languages such as DocBook.'},\n",
        "  u'GlossSee': u'markup',\n",
        "  u'GlossTerm': u'Standard Generalized Markup Language',\n",
        "  u'ID': u'SGML',\n",
        "  u'SortAs': u'SGML'}}"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Web scraping\n",
      "\n",
      "Sometimes we want to get data from a web page that does not provide an API to do so programmatically. In such cases, we have to resort to *web scraping*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pip install Scrapy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/bin/sh: 1: pip: not found\r\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not os.path.exists('dmoz'):\n",
      "    ! scrapy startproject dmoz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/bin/sh: 1: scrapy: not found\r\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file dmoz/dmoz/items.py\n",
      "import scrapy\n",
      "\n",
      "class DmozItem(scrapy.Item):\n",
      "    title = scrapy.Field()\n",
      "    link = scrapy.Field()\n",
      "    desc = scrapy.Field()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing dmoz/dmoz/items.py\n"
       ]
      },
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: 'dmoz/dmoz/items.py'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-16-841dc895290d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'file'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'dmoz/dmoz/items.py'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'import scrapy\\n\\nclass DmozItem(scrapy.Item):\\n    title = scrapy.Field()\\n    link = scrapy.Field()\\n    desc = scrapy.Field()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2160\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2161\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2162\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2163\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    701\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/site-packages/IPython/core/magics/osm.pyc\u001b[0m in \u001b[0;36mwritefile\u001b[1;34m(self, line, cell)\u001b[0m\n",
        "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/site-packages/IPython/core/magics/osm.pyc\u001b[0m in \u001b[0;36mwritefile\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'a'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'dmoz/dmoz/items.py'"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file dmoz/dmoz/spiders/dmoz_spider.py\n",
      "import scrapy\n",
      "\n",
      "from dmoz.items import DmozItem\n",
      "\n",
      "class DmozSpider(scrapy.Spider):\n",
      "    name = \"dmoz\"\n",
      "    allowed_domains = [\"dmoz.org\"]\n",
      "    start_urls = [\n",
      "        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/\",\n",
      "        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/\"\n",
      "    ]\n",
      "\n",
      "    def parse(self, response):\n",
      "        for sel in response.xpath('//ul/li'):\n",
      "            item = DmozItem()\n",
      "            item['title'] = sel.xpath('a/text()').extract()\n",
      "            item['link'] = sel.xpath('a/@href').extract()\n",
      "            item['desc'] = sel.xpath('text()').extract()\n",
      "            yield item"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cd dmoz\n",
      "scrapy crawl dmoz --nolog -o scraped_data.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dmoz = json.load(open('dmoz/scraped_data.json'))\n",
      "for item in dmoz:\n",
      "    if item['title'] and item['link']:\n",
      "        if item['link'][0].startswith('http'):\n",
      "            print '%s: %s' % (item['title'][0], item['link'][0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### HDF5\n",
      "\n",
      "HDF5 is a hierarchical format often used to store complex scientific data. For instance, Matlab now saves its data to HDF5. It is particularly useful to store complex hierarchical data sets with associated metadata, for example, the results of a computer simulation experiment.\n",
      "\n",
      "The main concepts associated with HDF5 are \n",
      "\n",
      "- file: container for hierachical data - serves as 'root' for tree\n",
      "- group: a node for a tree\n",
      "- dataset: array for numeric data - can be huge\n",
      "- attribute: small pieces of metadata that provide additional context"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import h5py\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# creating a HDF5 file\n",
      "import datetime\n",
      "\n",
      "if not os.path.exists('example.hdf5'):\n",
      "\n",
      "    with h5py.File('example.hdf5') as f:\n",
      "        project = f.create_group('project')\n",
      "        project.attrs.create('name', 'My project')\n",
      "        project.attrs.create('date', str(datetime.date.today()))\n",
      "\n",
      "        expt1 = project.create_group('expt1')\n",
      "        expt2 = project.create_group('expt2')\n",
      "        expt1.create_dataset('counts', (100,), dtype='i')\n",
      "        expt2.create_dataset('values', (1000,), dtype='f')\n",
      "\n",
      "        expt1['counts'][:] = range(100)\n",
      "        expt2['values'][:] = np.random.random(1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with h5py.File('example.hdf5') as f:\n",
      "    project = f['project']\n",
      "    print project.attrs['name']\n",
      "    print project.attrs['date']\n",
      "    print project['expt1']['counts'][:10]\n",
      "    print project['expt2']['values'][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Relational databases\n",
      "\n",
      "Relational databases are comprised of tables, where each row consists of a tuple of columns. Each row is uniquely identified by a *primary key*, and tables can be linked via *foreign keys*.\n",
      "\n",
      "We will illustrate the concepts of table querying the [Chinook database](http://chinookdatabase.codeplex.com/). From the online description, \"The Chinook data model represents a digital media store, including tables for artists, albums, media tracks, invoices and customers.\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image\n",
      "\n",
      "Image(url='http://lh4.ggpht.com/_oKo6zFhdD98/SWFPtyfHJFI/AAAAAAAAAMc/GdrlzeBNsZM/s800/ChinookDatabaseSchema1.1.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sqlite3\n",
      "\n",
      "# first connect to database and get a cursor for executing commands\n",
      "conn = sqlite3.connect('Chinook.db')\n",
      "cr = conn.cursor()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# What tables are in the database?\n",
      "cr.execute(\"select name from sqlite_master where type = 'table';\")\n",
      "print cr.fetchall()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# What is the structure of the Album table?\n",
      "cr.execute(\"select sql from sqlite_master where type = 'table' and name = 'Album';\" )\n",
      "print cr.fetchone()[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# What is the structure of the Artist table?\n",
      "cr.execute(\"select sql from sqlite_master where type = 'table' and name = 'Artist';\" )\n",
      "print cr.fetchone()[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# List a few items\n",
      "cr.execute(\"select * from Album limit 6\")\n",
      "cr.fetchall()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find the artist who performed on the Album 'Big Ones'\n",
      "cmd = \"\"\"\n",
      "select Artist.Name from Artist, Album \n",
      "where Artist.ArtistId = Album.ArtistId\n",
      "and Album.Title = 'Big Ones';\n",
      "\"\"\"\n",
      "cr.execute(cmd)\n",
      "cr.fetchall()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# clean up\n",
      "cr.close()\n",
      "conn.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Scrubbing data\n",
      "----\n",
      "\n",
      "Scrubbing data refers to the preprocessing needed to prepare data for analysis. This may involve removing particular rows or columns, handling missing data, fixing inconsistencies due to data entry errors, transforming dates, generating derived variables, combining data from multiple sources, etc. Unfortunately, there is no one method that can handle all of the posisble data preprocessing needs; however, some familiarity with Python and packages such as those illustrated above will go a long way.\n",
      "\n",
      "For a real-life example of the amount of work required, see the [Bureau of Labor Statistics (US Government)](http://okfnlabs.org/bad-data/ex/bls-us-employment/) example.\n",
      "\n",
      "Here we will illustrate some simple data cleaning tasks that can be done with `pandas`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file bad_data.csv\n",
      "# This is a comment\n",
      "# This is another comment\n",
      "name,gender,weight,height\n",
      "alice,f,60,1.56\n",
      "bob,m,72,1.75\n",
      "charles,m,,91\n",
      "david,m,84,1.82\n",
      "edgar,m,1.77,93\n",
      "fanny,f,45,1.45"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Supppose we wanted to find the average Body Mass Index (BMI) \n",
      "# from the data set above\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "df = pd.read_csv('bad_data.csv', comment='#')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Something is strange - the average height is 31 meters!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the height and weight to see\n",
      "plt.boxplot([df.weight, df.height]),;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.height > 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# weight and height appear to have been swapped\n",
      "# so we'll swap them back\n",
      "idx = df.height > 2\n",
      "df.ix[idx, 'height'], df.ix[idx, 'weight'] = df.ix[idx, 'weight'], df.ix[idx, 'height']\n",
      "df[df.height > 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# we migth want to impute the missing height\n",
      "# perhaps by predicting it from a model of the relationship\n",
      "# bewtween height, weight and gender\n",
      "# but for now we'll just ignore rows with mising data\n",
      "\n",
      "df['BMI'] = df['weight']/(df['height']*df['height'])\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# And finally, we calcuate the mean BMI by gender\n",
      "df.groupby('gender')['BMI'].mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color=red>Exercises</font>\n",
      "----"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**1**. Write the following sentences to a file \"hello.txt\" using `open` and `write`. There should be 3 lines in the resulting file.\n",
      "```\n",
      "Hello, world.\n",
      "Goodbye, cruel world.\n",
      "The world is your oyster.\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# YOUR CODE HERE\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**2**. Using a `for` loop and `open`, print only the lines from the file 'hello.txt' that begin wtih 'Hello' or 'The'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# YOUR CODE HERE\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**3**. Most of the time, tabular files can be read corectly using convenience functions from pandas. Sometimes, however, line-by-line processing of a file is unavoidable, typically when the file originated from an Excel spreadsheet. Use the `csv` module and a `for` loop to create a pandas DataFrame for the file `ugh.csv`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file ugh.csv\n",
      "# This is a comment\n",
      "# This is another comment\n",
      "name,weight,height\n",
      "alice, 60,1.56\n",
      "bob,72,1.75\n",
      "david,84,   1.82\n",
      "\n",
      "pooh,314.2,1.4\n",
      "# eeyore should be here but didn't come for follow up\n",
      "rabbit, 1.2,0.6\n",
      "\"king Rameses, the third\",85,1.82\n",
      "\n",
      "Notes: weight is in kg \n",
      "Note: height is in meters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The cleaned table should look like this\n",
      "import pandas as pd\n",
      "pd.read_csv('clean_ugh.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# YOUR CODE HERE\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**4**. Given the HDF5 file 'mystery.hdf5', plot a histogram of the `events` dataset in the subgroup `expt` of `simulation`. Give the plot a title of 'name (date)' where name and date are attributes of the `simulation` group."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# YOUR CODE HERE\n",
      "\n",
      "with h5py.File('mystery.hdf5') as f:\n",
      "    pass\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**5**. Make a table of the top 10 artists who have the most number of tracks in the SQLite3 database \"Chinook.db\". Since you wil take some time to master the arcana of SQL syntax, a template is provided for the SQL query. All you have to do is fill in the X's. This may require some Googling to figure out what the syntax means. It is also helpful to refer to the \"Chinook.db\" schema shown below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image\n",
      "\n",
      "Image(url='http://lh4.ggpht.com/_oKo6zFhdD98/SWFPtyfHJFI/AAAAAAAAAMc/GdrlzeBNsZM/s800/ChinookDatabaseSchema1.1.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# YOUR CODE HERE\n",
      "\n",
      "sql = \"\"\"\n",
      "select X, count(X) as total \n",
      "from X, X, X \n",
      "where X = X and X = X \n",
      "group by X\n",
      "order by X desc \n",
      "limit X;\n",
      "\"\"\"\n",
      "\n",
      "with sqlite3.connect('Chinook.db') as conn:\n",
      "    cr = conn.cursor()\n",
      "    cr.execute(sql) \n",
      "    for row in cr.fetchall():\n",
      "        print row\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}