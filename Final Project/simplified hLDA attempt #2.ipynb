{
 "metadata": {
  "name": "",
  "signature": "sha256:d0cac157254efb00af67edf2301233504523256356d6144da2bc11bd7c136f97"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class GibbsHDP(object):\n",
      "    \n",
      "    def __init__(self,filename,alpha,beta,gamma,k_0,k_max,a_alpha,b_alpha):\n",
      "        \n",
      "        self.dictionary,self.corpus,self.text_corpus,self.wordCounts,self.uniqueWords = text_munge(filename)\n",
      "        self.corpus = corpus\n",
      "        self.alpha = alpha\n",
      "        self.beta = beta\n",
      "        self.gamma = gamma\n",
      "        self.k = k_0\n",
      "        self.k_max = k_max\n",
      "        self.V = len(self.uniqueWords)\n",
      "        self.M = len(corpus)\n",
      "        self.a_alpha = a_alpha\n",
      "        self.b_alpha = b_alpha\n",
      "        self.NZM = np.zeros([k_max,self.M])\n",
      "        self.NZ = np.zeros([k_max,])\n",
      "        self.NWZ = np.zeros([self.V,k_max])\n",
      "        self.U_used = range(0,self.k)\n",
      "        self.U_unused = range(self.k,k_max)\n",
      "        self.z_mn = copy.deepcopy(corpus)\n",
      "        self.tau = np.ones([self.k+1])*0.1\n",
      "      \n",
      "    \n",
      "    \n",
      "    def iterate_sampler(self,n_iters):\n",
      "    \n",
      "        for iteration in range(0,n_iters):\n",
      "            for m,document in enumerate(self.corpus):\n",
      "                for n,word in enumerate(document):\n",
      "                    self.sample_topics(m,n)\n",
      "            self.prune_topics()\n",
      "            self.sample_tau()\n",
      "        \n",
      "        \n",
      "    def random_assign(self):\n",
      "        for m,document in enumerate(self.corpus):\n",
      "    \n",
      "            for n,word in enumerate(document):\n",
      "                k_new = np.random.multinomial(1,np.ones([self.k,])/((self.k))).dot(np.arange(0,self.k))\n",
      "                assert k_new in self.U_used\n",
      "                self.z_mn[m][n] = k_new\n",
      "                self.NZM[k_new,m]+=1\n",
      "                self.NWZ[word,k_new]+=1\n",
      "                self.NZ[k_new]+=1\n",
      "    \n",
      "    def sample_tau(self):\n",
      "        \n",
      "        m_k = np.zeros(self.k+1)\n",
      "        for idx,topic in enumerate(self.U_used):\n",
      "            counts = 0\n",
      "            for m in range(0,self.M):\n",
      "                for r in range(1,(self.NZM[topic,m]+1).astype(int)):\n",
      "                    assert topic in self.U_used\n",
      "                \n",
      "                    p_m = (self.alpha*self.tau[idx])/(self.alpha*self.tau[idx]+r-1)\n",
      "                \n",
      "                    if p_m>0.99999999:\n",
      "                        draw = 1\n",
      "                    else:\n",
      "                        draw = np.random.binomial(1,p_m)\n",
      "                \n",
      "                    counts += draw\n",
      "            m_k[idx] = counts\n",
      "                \n",
      "        assert m_k[-1] == 0\n",
      "        m_k[-1] = self.gamma\n",
      "        self.tau = np.random.dirichlet(m_k)\n",
      "        \n",
      "    def sample_topics(self,m,n):\n",
      "        p_z= np.zeros([self.k+1,])\n",
      "        word = self.corpus[m][n]       \n",
      "        self.NWZ[word,self.z_mn[m][n]]-=1\n",
      "        self.NZ[self.z_mn[m][n]]-=1\n",
      "        self.NZM[self.z_mn[m][n],m]-=1\n",
      "            \n",
      "        assert self.NWZ[word,self.z_mn[m][n]]>=0\n",
      "        assert self.NZ[self.z_mn[m][n]]>=0\n",
      "        assert self.NZM[self.z_mn[m][n],m]>=0\n",
      "            \n",
      "        for i in range(0,self.k):\n",
      "            p_z[i] = ((self.NWZ[word,self.U_used[i]]+self.beta)/ \n",
      "                (self.NZ[self.U_used[i]]+self.V*self.beta)*\n",
      "                ((self.NZM[self.U_used[i],m])+self.alpha*self.tau[i]))\n",
      "            assert p_z[i]>0\n",
      "                \n",
      "        assert p_z[-1] == 0\n",
      "        assert len(self.tau)==self.k+1\n",
      "        p_z[-1] = self.alpha * self.tau[-1] / self.V\n",
      "        draw = np.random.multinomial(1,p_z/np.sum(p_z))\n",
      "        if draw[-1]==1:\n",
      "            self.U_used,self.U_unused,z_new = new_topic(self.U_used,self.U_unused)\n",
      "            self.tau = self.sample_tau()\n",
      "        else:\n",
      "            z_new = draw[:-1].dot(self.U_used)\n",
      "    \n",
      "        assert (len(self.U_used) + len(self.U_unused)) == self.k_max\n",
      "        self.z_mn[m][n]=z_new\n",
      "        self.NWZ[word,z_new]+=1\n",
      "        self.NZ[z_new]+=1\n",
      "        self.NZM[z_new,m]+=1\n",
      "        \n",
      "    def new_topic(U_used,U_unused):\n",
      "        U_unused = np.sort(U_unused)\n",
      "        new_k = U_unused[0]\n",
      "        assert new_k not in U_used\n",
      "        np.delete(U_unused,0)\n",
      "        np.append(U_used,new_k)\n",
      "        return np.sort(U_used),U_unused,new_k \n",
      "    \n",
      "    def delete_topic(U_used,U_unused,idx):\n",
      "        val = U_used[idx]\n",
      "        np.delete(U_used,idx)\n",
      "        np.append(U_unused,val)\n",
      "        return np.sort(U_used),np.sort(U_unused)\n",
      "    \n",
      "    def prune_topics(self):\n",
      "        for idx,topic in enumerate(self.U_used):\n",
      "            if self.NZ[topic]==0:\n",
      "                assert np.sum(self.NWZ[:,topic]==0)\n",
      "                assert np.sum(self.NZM[topic,:]==0)\n",
      "                self.U_used,self.U_unused = delete_topic (self.U_used,self.U_unused,idx)\n",
      "                \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "GHDP = GibbsHDP('prince_alice.txt',0.1,0.1,1,3,5,1,1)\n",
      "GHDP.random_assign()\n",
      "GHDP.sample_tau()\n",
      "print tau\n",
      "GHDP.iterate_sampler(5)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  5.30070130e-01   4.69909623e-01   2.02463125e-05]\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print GHDP.tau"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  3.23661282e-01   3.23366155e-01   3.52752136e-01   2.20427553e-04]\n"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import csv\n",
      "import string\n",
      "\n",
      "import copy\n",
      "# assume format is documents delimited by line \n",
      "\n",
      "def text_munge(filename):\n",
      "    \n",
      "    f = open(filename)\n",
      "    text = f.read()\n",
      "    text = text.lower()\n",
      "    \n",
      "    text = text.translate(string.maketrans(\"\",\"\"), string.punctuation)\n",
      "    split_text = text.split('\\r\\n\\r')\n",
      "\n",
      "    for i,doc in enumerate(split_text):\n",
      "        d = doc.replace('\\n',' ')\n",
      "        d = d.replace('\\r','')\n",
      "        split_text[i]=d\n",
      "        \n",
      "    split_text = filter(None,split_text)\n",
      "\n",
      "    docs=[]\n",
      "    for paragraph in split_text:\n",
      "        doc = paragraph.split(\" \")\n",
      "        docs.append(doc)\n",
      "\n",
      "\n",
      "    uniqueWords=[]\n",
      "    wordCounts=[]\n",
      "\n",
      "\n",
      "    for doc in docs:\n",
      "    \n",
      "        for word in doc:\n",
      "       \n",
      "            if word in uniqueWords:\n",
      "                for v,term in enumerate(uniqueWords):\n",
      "                    if term==word:\n",
      "                        wordCounts[v]+=1\n",
      "                \n",
      "            else:\n",
      "                uniqueWords.append(word)\n",
      "                wordCounts.append(1)\n",
      "    \n",
      "    V=len(uniqueWords) \n",
      "    dictionary = dict(zip(uniqueWords,range(0,V)))\n",
      "\n",
      "    integer_docs=[]\n",
      "\n",
      "    for doc in docs:\n",
      "        integer_doc=[]\n",
      "        for word in doc:\n",
      "            integer_doc.append(dictionary[word])\n",
      "        \n",
      "        integer_docs.append(integer_doc)\n",
      " \n",
      "\n",
      "    dictionary = {v: k for k, v in dictionary.items()}\n",
      "    \n",
      "    return dictionary,integer_docs,docs,wordCounts,uniqueWords\n",
      "\n",
      "\n",
      "\n",
      "dictionary,corpus,text_corpus,wordCounts,uniqueWords = text_munge('prince_alice.txt')\n",
      "\n",
      "K0 = 3\n",
      "KMax = 5\n",
      "alpha = 0.1\n",
      "gamma = 1\n",
      "\n",
      "U_used,U_unused,z_mn,NZM,NWZ,NZ = HDP_init(corpus,uniqueWords,K0,KMax)\n",
      "\n",
      "tau = sample_tau(K0,U_used,tau,gamma,NZM,alpha)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "K0 = 2\n",
      "KMax = 5\n",
      "alpha = 0.1\n",
      "gamma = 1\n",
      "beta = 0.1\n",
      "\n",
      "U_used,U_unused,z_mn,NZM,NWZ,NZ = HDP_init(corpus,uniqueWords,K0,KMax)\n",
      "\n",
      "tau = sample_tau(K0,U_used,tau,gamma,NZM,alpha)\n",
      "for i in range(0,100):\n",
      "    print NZ\n",
      "    for m,document in enumerate(corpus):\n",
      "        \n",
      "            \n",
      "        for n,word in enumerate(document):\n",
      "        \n",
      "            tau,z,NWZ,NZM,NZ,U_used,U_unused = HDP_z_assignment(m,n,word,len(U_used),KMax,len(uniqueWords),alpha,beta,gamma,tau,z_mn,NWZ,NZM,NZ,U_used,U_unused)\n",
      "        \n",
      "   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 71059.  70768.      0.      0.      0.]\n",
        "[ 70604.  71223.      0.      0.      0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 70885.  70942.      0.      0.      0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 70784.  71043.      0.      0.      0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 71200.  70627.      0.      0.      0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 70931.  70896.      0.      0.      0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 71365.  70462.      0.      0.      0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 71584.  70243.      0.      0.      0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 71653.  70174.      0.      0.      0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 71775.  70052.      0.      0.      0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 71790.  70037.      0.      0.      0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[  7.20000000e+04   6.98260000e+04   1.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 72074.  69753.      0.      0.      0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 72251.  69576.      0.      0.      0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 72496.  69331.      0.      0.      0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-69-631c237dbc0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mtau\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNWZ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNZM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNZ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mU_used\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mU_unused\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHDP_z_assignment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU_used\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mKMax\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniqueWords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz_mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNWZ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNZM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNZ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mU_used\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mU_unused\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-68-3a345d98659b>\u001b[0m in \u001b[0;36mHDP_z_assignment\u001b[1;34m(m, n, word, L, K_max, V, alpha, beta, gamma, tau, z, NWZ, NZM, NZ, U_used, U_unused)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mdraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_z\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mU_used\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mU_unused\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_topic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU_used\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mU_unused\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   1714\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m         return _methods._sum(a, axis=axis, dtype=dtype,\n\u001b[1;32m-> 1716\u001b[1;33m                             out=out, keepdims=keepdims)\n\u001b[0m\u001b[0;32m   1717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mproduct\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "with open('prince_alice_ks_z.csv', 'w') as csvfile:\n",
      "    writer = csv.writer(csvfile)\n",
      "    writer.writerows(z)\n",
      "\n",
      "with open('prince_alice_ks_docs.csv', 'w') as csvfile:\n",
      "    writer = csv.writer(csvfile)\n",
      "    writer.writerows(text_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def HDP_init(corpus,uniqueWords,K_0,K_max):\n",
      "    M = len(corpus)\n",
      "    K = K_0\n",
      "    V = len(uniqueWords)\n",
      "    U_used = range(0,K)\n",
      "    U_unused = range(K,K_max)\n",
      "    z_mn = copy.deepcopy(corpus)\n",
      "    NZM = np.zeros([K_max,M])\n",
      "    NWZ = np.zeros(([V,K_max]))\n",
      "    NZ = np.zeros([K_max,])\n",
      "\n",
      "    # initalize counts\n",
      "    for m,document in enumerate(corpus):\n",
      "    \n",
      "        for n,word in enumerate(document):\n",
      "            k_new = np.random.multinomial(1,np.ones([K,])/((K))).dot(np.arange(0,K))\n",
      "            assert k_new in U_used\n",
      "            z_mn[m][n] = k_new\n",
      "            NZM[k_new,m]+=1\n",
      "            NWZ[word,k_new]+=1\n",
      "            NZ[k_new]+=1\n",
      "    return U_used,U_unused,z_mn,NZM,NWZ,NZ\n",
      "      \n",
      "\n",
      "def HDP_z_assignment(m,n,word,L,K_max,V,alpha,beta,gamma,tau,z,NWZ,NZM,NZ,U_used,U_unused):\n",
      "   \n",
      "    p_z= np.zeros([L+1,])\n",
      "               \n",
      "    NWZ[word,z[m][n]]-=1\n",
      "    NZ[z[m][n]]-=1\n",
      "    NZM[z[m][n],m]-=1\n",
      "            \n",
      "    assert NWZ[word,z[m][n]]>=0\n",
      "    assert NZ[z[m][n]]>=0\n",
      "    assert NZM[z[m][n],m]>=0\n",
      "            \n",
      "    for i in range(0,L):\n",
      "         p_z[i] = (NWZ[word,U_used[i]]+beta)/(NZ[U_used[i]]+V*beta)*((NZM[U_used[i],m])+alpha*tau[i])\n",
      "                \n",
      "               \n",
      "         assert p_z[i]>0\n",
      "                \n",
      "    assert p_z[-1] == 0\n",
      "    assert len(tau)==L+1\n",
      "    p_z[-1] = alpha * tau[-1] / V\n",
      "    \n",
      "    \n",
      "    \n",
      "    draw = np.random.multinomial(1,p_z/np.sum(p_z))\n",
      "    if draw[-1]==1:\n",
      "        U_used,U_unused,z_new = new_topic(U_used,U_unused)\n",
      "        tau = sample_tau(L,U_used,tau,gamma,NZM,alpha)\n",
      "    else:\n",
      "        z_new = draw[:-1].dot(U_used)\n",
      "    \n",
      "    assert (len(U_used) + len(U_unused)) == K_max\n",
      "    z[m][n]=z_new\n",
      "       \n",
      "    NWZ[word,z_new]+=1\n",
      "    NZ[z_new]+=1\n",
      "    NZM[z_new,m]+=1\n",
      "    \n",
      "            \n",
      "            \n",
      "    return tau,z,NWZ,NZM,NZ,U_used,U_unused\n",
      "\n",
      "def new_topic(U_used,U_unused):\n",
      "    U_unused = np.sort(U_unused)\n",
      "    new_k = U_unused[0]\n",
      "    assert new_k not in U_used\n",
      "    np.delete(U_unused,0)\n",
      "    np.append(U_used,new_k)\n",
      "    return np.sort(U_used),U_unused,new_k\n",
      "\n",
      "def del_topic(U_used,U_unused,k_index,nz):\n",
      "    assert nz[U_used[k_index]]==0\n",
      "    empty_k = U_used[k_index]\n",
      "    np.delete(U_used,k_index)\n",
      "    \n",
      "    assert empty_k not in U_unused\n",
      "    np.append(U_unused,empty_k)\n",
      "    \n",
      "    return np.sort(U_used),np.sort(U_unused)\n",
      "    \n",
      "def sample_tau(K,U_used,tau,gamma,n_zm,alpha):\n",
      "    M = n_zm.shape[1]\n",
      "    m_k = np.zeros(K+1)\n",
      "    for k in U_used:\n",
      "        counts = 0\n",
      "        for m in range(0,M):\n",
      "            for r in range(1,(n_zm[k,m]+1).astype(int)):\n",
      "                assert k in U_used\n",
      "                \n",
      "                p_m = (alpha*tau[k])/(alpha*tau[k]+r-1)\n",
      "                \n",
      "                if p_m>0.99999999:\n",
      "                    draw = 1\n",
      "                else:\n",
      "                    draw = np.random.binomial(1,p_m)\n",
      "                \n",
      "                counts += draw\n",
      "        m_k[k] = counts\n",
      "                \n",
      "    assert m_k[-1] == 0\n",
      "    m_k[-1] = gamma\n",
      "    tau = np.random.dirichlet(m_k)\n",
      "    return tau\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### This code is based off a technical note written in 2011 by Gregor Heinrich: \"Infinite LDA - Implementing the HDP with minimum code complexity\"\n",
      "\n",
      "# CRP parameter\n",
      "gamma = 1.5\n",
      "\n",
      "# Initial topic dimension\n",
      "\n",
      "K_0 = 5\n",
      "\n",
      "# Maximum possible number of topics\n",
      "K_max = 5\n",
      "\n",
      "# Hyperparameter on Dirichlet distribution\n",
      "alpha = 1\n",
      "\n",
      "# Hyperparameter on Dirichlet distribution\n",
      "beta = 0.1\n",
      "\n",
      "a_gamma = 0.1\n",
      "b_gamma = 0.1\n",
      "\n",
      "# Initial guess \n",
      "tau = np.ones([K_0,])\n",
      "\n",
      "# Number of iterations to sample over\n",
      "iters = 100\n",
      "\n",
      "\n",
      "a_alpha = 5\n",
      "\n",
      "b_alpha = 0.1\n",
      "\n",
      "dictionary,corpus,wordCounts,uniqueWords = text_munge('prince.txt')\n",
      "\n",
      "M = len(corpus)\n",
      "K = K_0\n",
      "V = len(uniqueWords)\n",
      "\n",
      "U_used = range(0,K)\n",
      "U_unused = range(K,K_max+1)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "z_mn = copy.deepcopy(corpus)\n",
      "n_mk = np.zeros([M,K_max])\n",
      "n_kt = np.zeros(([K_max,V]))\n",
      "n_k = np.zeros([K_max,])\n",
      "\n",
      "# initalize counts\n",
      "for m,document in enumerate(corpus):\n",
      "    \n",
      "    for n,word in enumerate(document):\n",
      "        k_new = np.random.multinomial(1,np.ones([K,])/((K))).dot(np.arange(0,K))\n",
      "        assert k_new in U_used\n",
      "        z_mn[m][n] = k_new\n",
      "        n_mk[m,k_new]+=1\n",
      "        n_kt[k_new,word]+=1\n",
      "        n_k[k_new]+=1\n",
      "      \n",
      "        \n",
      "term_count = np.sum(n_mk[:])\n",
      "# get initial sample of tau \n",
      "\n",
      "m_k = np.zeros(K+1)\n",
      "for k in U_used:\n",
      "    counts = 0\n",
      "    for m in range(0,M):\n",
      "        for r in range(1,(n_mk[m,k]+1).astype(int)):\n",
      "            assert k in U_used\n",
      "            p_m = (alpha*tau[k])/(alpha*tau[k]+r-1)\n",
      "                       \n",
      "            if p_m > .9999999:\n",
      "                draw = 1\n",
      "                \n",
      "            else:               \n",
      "                draw = np.random.binomial(1,p_m)\n",
      "            counts += draw\n",
      "    m_k[k] = counts\n",
      "                \n",
      "assert m_k[-1] == 0\n",
      "m_k[-1] = gamma\n",
      "tau = np.random.dirichlet(m_k)\n",
      "print 'tau after initialization: ',tau\n",
      "assert len(tau)==(len(U_used)+1)\n",
      "# do Gibbs Sampling\n",
      "\n",
      "for i in range(0,iters):\n",
      "    \n",
      "    print 'iteration ',i\n",
      "    print 'K:' ,K\n",
      "    print 'n_k: ',n_k\n",
      "    for m in range(0,M):\n",
      "        assert np.sum(n_mk[:])==np.sum(n_kt[:]) # check to make sure number of counts is conserved and there are no spurious count increments or decrements\n",
      "        document = corpus[m]\n",
      "        for n,word in enumerate(document):\n",
      "            \n",
      "          \n",
      "            \n",
      "            if n_kt[z_mn[m][n],word]==0:\n",
      "                print 'ABOUT TO SUBTRACT FROM ZERO!  ',m,n\n",
      "                print z_mn[m][n]\n",
      "            n_mk[m,z_mn[m][n]]-=1\n",
      "            n_kt[z_mn[m][n],word]-=1\n",
      "            n_k[z_mn[m][n]]-=1\n",
      "            \n",
      "          \n",
      "            assert z_mn[m][n] in U_used\n",
      "            assert n_mk[m,z_mn[m][n]] > -1\n",
      "            assert n_kt[z_mn[m][n],word] > -1\n",
      "            assert n_k[z_mn[m][n]] > -1\n",
      "            p_k = np.zeros([len(U_used)+1,])\n",
      "            for idx,k in enumerate(U_used):\n",
      "                p_k[idx] = n_mk[m,k] + (alpha * tau[idx]) * (n_kt[k,word] + beta) / (n_k[k] + beta * V)\n",
      "            assert p_k[-1] == 0\n",
      "            \n",
      "            p_k[-1] = alpha * tau[K] / V\n",
      "            \n",
      "            draw = np.random.multinomial(1,p_k/np.sum(p_k))\n",
      "            \n",
      "            assert len(draw) == K+1\n",
      "            \n",
      "            # creation of new topic with this word as its first assignment\n",
      "            if (draw[-1] == 1) and (K_max != K):\n",
      "                k_new = U_unused.pop(0)\n",
      "                K += 1\n",
      "                n_mk[m,k_new] += 1\n",
      "                n_k[k_new] += 1\n",
      "                n_kt[k_new,word] += 1\n",
      "                U_used.append(k_new)\n",
      "                m_k = np.zeros(K+1)\n",
      "                for idx,k in enumerate(U_used):\n",
      "                    counts = 0\n",
      "                    for q in range(0,M):\n",
      "                        for r in range(1,(n_mk[q,k]+1).astype(int)):\n",
      "                            if tau[idx]>0:\n",
      "                                p_m = (alpha*tau[idx])/(alpha*tau[idx]+r-1)\n",
      "                            else:\n",
      "                                p_m = 0\n",
      "                           \n",
      "                       \n",
      "                            if p_m > .9999999:\n",
      "                                draw = 1\n",
      "                \n",
      "                            else:               \n",
      "                                draw = np.random.binomial(1,p_m)\n",
      "                            counts += draw\n",
      "                    m_k[idx] = counts\n",
      "                assert m_k[-1] == 0\n",
      "                m_k[-1] = gamma\n",
      "               \n",
      "                tau = np.random.dirichlet(m_k)\n",
      "               \n",
      "                assert len(tau)==(len(U_used)+1)\n",
      "                \n",
      "            # new assignment of z_mn to existing topic    \n",
      "            else:\n",
      "                k_new = draw[:-1].dot(U_used)\n",
      "                \n",
      "                #print n_k\n",
      "                n_mk[m,k_new] += 1\n",
      "                n_k[k_new] += 1\n",
      "                n_kt[k_new,word] += 1\n",
      "            \n",
      "            \n",
      "            #print 'm: ',m ,' n: ',n,' k_new: ',k_new, '  K:',K\n",
      "            z_mn[m][n] = k_new\n",
      "    # prune unused topic  \n",
      "    for k in U_used:\n",
      "        if n_k[k] == 0:\n",
      "            \n",
      "            assert np.sum(n_mk[:,k])==0\n",
      "            assert np.sum(n_kt[k,:])==0\n",
      "            len_u = len(U_used)\n",
      "            U_used.remove(k)\n",
      "            assert len(U_used)==(len_u-1)\n",
      "            U_unused.insert(0,k)\n",
      "            assert np.sum(n_mk[:,k]) == 0\n",
      "            assert np.sum(n_kt[k,:]) == 0\n",
      "            K-=1\n",
      "    # sample tau for the new, updated topic list\n",
      "    m_k = np.zeros(K+1)\n",
      "   \n",
      "    for idx,k in enumerate(U_used):\n",
      "        \n",
      "        \n",
      "        counts = 0\n",
      "        for m in range(0,M):\n",
      "            for r in range(1,(n_mk[m,k]+1).astype(int)):\n",
      "                if tau[idx]>0:\n",
      "                    p_m = (alpha*tau[idx])/(alpha*tau[idx]+r-1)\n",
      "                else:\n",
      "                    p_m = 0\n",
      "                       \n",
      "                if p_m > .9999999:\n",
      "                    draw = 1\n",
      "                \n",
      "                else:               \n",
      "                    draw = np.random.binomial(1,p_m)\n",
      "                counts += draw\n",
      "        m_k[idx] = counts\n",
      "              \n",
      "    assert m_k[-1] == 0\n",
      "    m_k[-1] = gamma\n",
      "    tau = np.random.dirichlet(m_k)\n",
      "    assert len(tau)==(len(U_used)+1)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    # sample hyperparameters\n",
      "    TT = np.sum(m_k)\n",
      "    u = np.random.binomial(1,TT/(TT+gamma))\n",
      "    v = np.random.beta(gamma+1,TT)\n",
      "    gamma = np.random.gamma(a_gamma + K - 1 + u, b_gamma - np.log(v))\n",
      "    n_m = np.sum(n_mk,axis=1)\n",
      "    u_m = np.zeros([len(n_m),])\n",
      "    v_m = np.zeros([len(n_m),])\n",
      "    for idx,val in enumerate(n_m.tolist()):\n",
      "        u_m[idx] = np.random.binomial(1,val/(val + alpha))\n",
      "        v_m[idx] = np.random.beta(alpha+1,val)\n",
      "    alpha = np.random.gamma(a_alpha + TT - np.sum(u_m), b_alpha - np.sum(np.log(v_m)))\n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}